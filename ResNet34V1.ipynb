{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artistic-taylor",
   "metadata": {},
   "source": [
    "# WordNet Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "wordnet_path = '/data/image-net/ILSVRC2015/devkit/data/map_clsloc.txt'\n",
    "wordnet_dic = {}\n",
    "\n",
    "with open(wordnet_path) as file:\n",
    "    for line in file:\n",
    "        wordnet_dic[line.split()[0]] = line.split()\n",
    "        \n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(list(wordnet_dic.keys()))\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le.transform(['n02119789', 'n02100735', 'n02110185', 'n02096294']))\n",
    "\n",
    "print(le.inverse_transform([278, 212, 250, 193]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordnet_label_encoder(wordnet_label):\n",
    "    label = le.transform([wordnet_label])[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-request",
   "metadata": {},
   "source": [
    "# ImageNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print('executing_eagerly = ' + str(tf.executing_eagerly()))\n",
    "\n",
    "# Reads an image from a file, decodes it into a dense tensor\n",
    "def load_image(filename):\n",
    "    wordnet_label = tf.strings.split(filename, os.sep)[-2]\n",
    "    label = tf.numpy_function(wordnet_label_encoder, [wordnet_label], [tf.int64])\n",
    "    label = tf.squeeze(label)\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def show(image, label):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_train_dir = '/data/image-net/ILSVRC2012_img_train/'\n",
    "imagenet_files = tf.data.Dataset.list_files(imagenet_train_dir + '*/*')\n",
    "imagenet_train_ds = imagenet_files.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in imagenet_train_ds.take(5):\n",
    "    show(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-breed",
   "metadata": {},
   "source": [
    "# ImageNet Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transform\n",
    "\n",
    "image_size = [224, 224]\n",
    "\n",
    "def image_transform(image, label):\n",
    "    # resize\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    # normalize\n",
    "    return image, label\n",
    "\n",
    "imagenet_train_ds = imagenet_train_ds.map(image_transform, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in imagenet_train_ds.take(5):\n",
    "    show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "batch_size = 32\n",
    "\n",
    "imagenet_train_ds = imagenet_train_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefetch\n",
    "imagenet_train_ds = imagenet_train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache \n",
    "imagenet_train_ds = imagenet_train_ds.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-person",
   "metadata": {},
   "source": [
    "# ResNet34V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNetV1Block import identity_block\n",
    "from ResNetV1Block import identity_block_downsampling\n",
    "\n",
    "\n",
    "def ResNet34V1(\n",
    "        input_shape=(224, 224, 3),\n",
    "        classes=1000,\n",
    "        classifier_activation='softmax'):\n",
    "    \n",
    "    img_input = keras.layers.Input(shape=input_shape, name='input')\n",
    "\n",
    "    # stage1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same', name='stage1_conv')(img_input)\n",
    "    x = keras.layers.BatchNormalization(axis=-1, name='stage1_bn')(x)\n",
    "    x = keras.layers.ReLU(name='stage1_relu')(x)\n",
    "    \n",
    "    # stage2\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='stage2_pool')(x)\n",
    "    x = identity_block(x, filters=64, stage='stage2', block='a')\n",
    "    x = identity_block(x, filters=64, stage='stage2', block='b')\n",
    "    x = identity_block(x, filters=64, stage='stage2', block='c')\n",
    "\n",
    "    # stage3\n",
    "    x = identity_block_downsampling(x, filters=128, stage='stage3', block='a')\n",
    "    x = identity_block(x, filters=128, stage='stage3', block='b')\n",
    "    x = identity_block(x, filters=128, stage='stage3', block='c')\n",
    "    x = identity_block(x, filters=128, stage='stage3', block='d')\n",
    "    \n",
    "    # stage4\n",
    "    x = identity_block_downsampling(x, filters=256, stage='stage4', block='a')\n",
    "    x = identity_block(x, filters=256, stage='stage4', block='b')\n",
    "    x = identity_block(x, filters=256, stage='stage4', block='c')\n",
    "    x = identity_block(x, filters=256, stage='stage4', block='d')\n",
    "    x = identity_block(x, filters=256, stage='stage4', block='e')\n",
    "    x = identity_block(x, filters=256, stage='stage4', block='f')\n",
    "    \n",
    "    # stage5\n",
    "    x = identity_block_downsampling(x, filters=512, stage='stage5', block='a')\n",
    "    x = identity_block(x, filters=512, stage='stage5', block='b')\n",
    "    x = identity_block(x, filters=512, stage='stage5', block='c')\n",
    "    \n",
    "    # classifier\n",
    "    x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = keras.layers.Dense(units=classes, activation=classifier_activation, name='predictions')(x)\n",
    "\n",
    "    # Create model.\n",
    "    inputs = img_input\n",
    "    model = keras.Model(inputs=inputs, outputs=x, name='resnet34_v1')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-jason",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ResNet34V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-mississippi",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"resnet34_v1.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-channels",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers - losses - metrics\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True, name='SGD')\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs = model(x_batch, training=True)\n",
    "        loss_value = loss_fn(y, probs)\n",
    "        loss_value += sum(model.losses)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    \n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss_value)))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    if val_dataset is not None:\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            test_step(x_batch_val, y_batch_val)\n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        \n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-straight",
   "metadata": {},
   "source": [
    "# Training checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-noise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    # Path where to save the model\n",
    "    # The two parameters below mean that we will overwrite\n",
    "    # the current checkpoint if and only if\n",
    "    # the `val_loss` score has improved.\n",
    "    # The saved model name will include the current epoch.\n",
    "    filepath=\"resnet34_v1_{epoch}\",\n",
    "    save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    # Stop training when `val_loss` is no longer improving\n",
    "    monitor=\"val_loss\",\n",
    "    # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "    min_delta=1e-2,\n",
    "    # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "learning_rate_schedules = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "tensor_board = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"tensor_board_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    checkpoint,\n",
    "    learning_rate_schedules,\n",
    "    tensor_board\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
